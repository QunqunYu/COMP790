%================================================================

\documentclass[11pt]{article}

\usepackage{amsgen,amsmath,amstext,amsbsy,amsopn,amssymb,amscd}
\usepackage{graphicx}% Include figure files

\usepackage{epsfig}
\usepackage{cases}
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{subfigure}
\usepackage{color}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{placeins}
\usepackage{hyperref}
\textwidth 7.5in \textheight 9.5in \topmargin -1in \oddsidemargin -.5in
\parskip .1in
\renewcommand{\baselinestretch}{1.2} % double spaced

\numberwithin{equation}{section}

\newcommand{\iid}{\stackrel{\mathrm{iid}}{\sim}}
\newcommand{\refeq}[1]{Equation (\ref{#1})} % Text Environment

\numberwithin{equation}{section}
%\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{mydef}{Definition}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{prop}{Proposition}[section]

\newcommand{\so}{{\textsc{Solution.\;\;}}}
\newcommand{\pf}{\textsc{Proof:\;\;}}
\newcommand{\pb}[1]{\vspace{.2in}\noindent{\bf #1.}}
\newcommand{\ce}{\textsc{Counter Example.\;\;}}

%% \newcommand {\reals}  {{\rm I \! R}}
\newcommand {\reals}  {\mathbb{R}}
\newcommand {\eps}  {{\epsilon}}      % sheer laziness

\newcommand{\bbR}{\mathbb{R}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cM}{{\mathcal{M}}}
\newcommand{\Mall}{{\mathcal{M}_{\rm all}}}
\newcommand{\tcM}{{\tilde{\mathcal{M}}}}
\newcommand{\cN}{{\mathcal{N}}}

\newcommand{\0}{{\mathbf{0}}}
\newcommand{\1}{{\mathbf{1}}}
\renewcommand{\a}{{\mathbf{a}}}
\renewcommand{\b}{{\mathbf{b}}}
\renewcommand{\c}{{\mathbf{c}}}
\renewcommand{\d}{{\mathbf{d}}}
\newcommand{\e}{{\mathbf{e}}}
\newcommand{\f}{{\mathbf{f}}}
\renewcommand{\l}{{\boldsymbol{l}}}
\newcommand{\ls}{{\boldsymbol{\bar{l}}}}
\renewcommand{\o}{{\mathbf{o}}}
\newcommand{\p}{{\mathbf{p}}}
\newcommand{\q}{{\mathbf{q}}}
\newcommand{\res}{{\mathbf{r}}}
\newcommand{\tres}{{\mathbf{\tilde{r}}}}
\renewcommand{\u}{{\mathbf{u}}}
\renewcommand{\v}{{\mathbf{v}}}
\newcommand{\w}{{\mathbf{w}}}
\newcommand{\x}{{\mathbf{x}}}
\newcommand{\y}{{\mathbf{y}}}
\newcommand{\z}{{\mathbf{z}}}
\newcommand{\A}{{\mathbf{A}}}
\newcommand{\B}{{\mathbf{B}}}
\newcommand{\C}{{\mathbf{C}}}
\newcommand{\D}{{\mathbf{D}}}
\newcommand{\E}{{\mathbf{E}}}
\newcommand{\F}{{\mathrm{F}}}
\newcommand{\G}{{\mathbf{G}}}
\renewcommand{\H}{{\mathbf{H}}}
\newcommand{\I}{{\mathbf{I}}}
\newcommand{\J}{{\mathbf{J}}}
\renewcommand{\L}{{\mathbf{L}}}
\newcommand{\M}{{\mathbf{M}}}
\renewcommand{\O}{{\mathbf{O}}}
\renewcommand{\P}{{\mathbf{P}}}
\newcommand{\Q}{{\mathbf{Q}}}
\newcommand{\R}{{\mathbf{R}}}
\renewcommand{\S}{{\mathbf{S}}}
\newcommand{\U}{{\mathbf{U}}}
\newcommand{\V}{{\mathbf{V}}}
\newcommand{\W}{{\mathbf{W}}}
\newcommand{\X}{{\mathbf{X}}}
\newcommand{\Y}{{\mathbf{Y}}}
\newcommand{\Z}{{\mathbf{Z}}}

\newcommand{\KSch}{{K_{\rm Sch}}}
\newcommand{\Korth}{{K_{\rm orth}}}

\newcommand{\Beta}{{\mathrm{B}}}
\newcommand{\hM}{{\mathrm{\hat{M}}}}
\newcommand{\hF}{{F^Z_{p-1}}}
\newcommand{\rM}{\mathrm{M}}
\newcommand{\rF}{\mathrm{F}}
\newcommand{\Unif}{\mathrm{Unif}}

\newcommand{\tP}{{\mathbf{\tilde{P}}}}
\newcommand{\tX}{{\mathbf{\tilde{X}}}}
\newcommand{\tY}{{\mathbf{\tilde{Y}}}}
\newcommand{\tBmu}{{\mathbf{\tilde{{\boldsymbol{\mu}}}}}}
\newcommand{\tl}{{\mathbf{\tilde{l}}}}
\newcommand{\tu}{{\mathbf{\tilde{u}}}}
\newcommand{\tv}{{\mathbf{\tilde{v}}}}
\newcommand{\tM}{{\tilde{\mathrm{M}}}}

\newcommand{\bX}{{\mathbf{\bar{X}}}}
\newcommand{\by}{{\mathbf{\bar{y}}}}

\newcommand{\Bbeta}{{\boldsymbol{\beta}}}
\newcommand{\Beps}{{\boldsymbol{\epsilon}}}
\newcommand{\Bmu}{{\boldsymbol{\mu}}}
\newcommand{\Btheta}{{\boldsymbol{\theta}}}

\newcommand{\hBb}{{\boldsymbol{\hat{\beta}}}}
\newcommand{\hb}{{\hat{\beta}}}
\newcommand{\hY}{{\mathbf{\hat{Y}}}}
\newcommand{\htY}{{\mathbf{\tilde{\hat{Y}}}}}
\newcommand{\hsig}{{\hat{\sigma}}}
\newcommand{\hH}{{\hat{H}}}

\newcommand{\bPi}{\boldsymbol{\Pi}}
\newcommand{\bPhi}{\boldsymbol{\Phi}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bOmega}{\boldsymbol{\Omega}}
\newcommand{\bDelta}{\boldsymbol{\Delta}}
\newcommand{\Btau}{\boldsymbol{\tau}}
\newcommand{\Bphi}{\boldsymbol{\phi}}
\newcommand{\Bgamma}{\boldsymbol{\gamma}}
\newcommand{\Bzeta}{\boldsymbol{\zeta}}
\newcommand{\Bpsi}{\boldsymbol{\psi}}

%% \newcommand{\Prob}{{\rm P}}
%% \newcommand{\Ept}{{\rm E}}
\newcommand{\Var}{{\rm Var}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\var}{\mathrm{var}}
\newcommand{\spanof}{\mathrm{span}}
\newcommand{\CI}{\mathrm{CI}}
%\newcommand{\tr}{{\rm tr}}
\newcommand{\CV}{\operatorname{\rm CV}}
\newcommand{\GCV}{\operatorname{\rm GCV}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\pval}{\mathrm{pval}}
\newcommand{\SPAR}{\mathrm{SPAR}}
\newcommand{\SPARone}{\hbox{\tiny\rm S\!P\!A\!R\!1}}
\newcommand{\VIF}{{V\!I\!F}}

\newcommand{\pnorm}[1]{{[\![}#1{]\!]}}
\newcommand{\plangle}{{\langle\!\langle}}
\newcommand{\prangle}{{\rangle\!\rangle}}
\newcommand{\argmin}{\mathrm{argmin}}
\newcommand{\argmax}{\mathrm{argmax}}
\newcommand{\ip}[2]{\langle #1 , #2 \rangle}
\newcommand{\blue}[1]{{\color{blue}#1}}
\newcommand{\red}[1]{{\color{red}#1}}


\newcommand{\vX}{\vec{\mathbf{X}}}
\newcommand{\Beeta}{{\boldsymbol{\eta}}}
\newcommand{\Bsigma}{\boldsymbol{\sigma}}
\newcommand{\ed}{\hfill$\square$}



\newcommand{\Tcal}{\mathcal{T}}
\newcommand{\acal}{\mathcal{A}}
\newcommand{\bcal}{\mathcal{B}}
\newcommand{\ccal}{\mathcal{C}}
\newcommand{\dcal}{\mathcal{D}}
\newcommand{\ecal}{\mathcal{E}}
\newcommand{\fcal}{\mathcal{F}}
\newcommand{\gcal}{\mathcal{G}}
\newcommand{\hcal}{\mathcal{H}}
\newcommand{\kcal}{\mathcal{K}}
\newcommand{\lcal}{\mathcal{L}}
\newcommand{\ncal}{\mathcal{N}}
\newcommand{\pcal}{\mathcal{P}}
\newcommand{\rcal}{\mathcal{R}}
\newcommand{\scal}{\mathcal{S}}
\newcommand{\tcal}{\mathcal{T}}
\newcommand{\vcal}{\mathcal{V}}
\newcommand{\wcal}{\mathcal{W}}
\newcommand{\tacal}{$\mathcal{A}$}
\newcommand{\tbcal}{$\mathcal{B}$}
\newcommand{\tccal}{$\mathcal{C}$}
\newcommand{\tfcal}{$\mathcal{F}$}
\newcommand{\tgcal}{$\mathcal{G}$}
\newcommand{\thcal}{$\mathcal{H}$}
\newcommand{\tscal}{$\mathcal{S}$}




%----------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------


\begin{title}
{\Large\bf Machine Learning Project Proposal
}
\end{title}
\author{Yanqian Wang and Qunqun Yu}
\date{October 2, 2015}
\maketitle

%----------------------------------------------------------------

%\begin{abstract}
%\end{abstract}
%
%%----------------------------------------------------------------
%
%{\bf Keywords:}
%
%%----------------------------------------------------------------
%

\section{Literature Review}
\subsection{ A review of the Deep Learning techniques in 3D object recognition and document recognition by Qunqun Yu}
This part will focus on the review of several developed deep learning techniques and their advantages in the applications to computer vision such as shape recognition and documentary recognition.
\begin{itemize}
\item The understanding of techniques of restricted boltzmann machine (RBM), deef belief networks, and convolutional net.
\item The comparison of above techniques based on error rates and convergence rates.
\item Revisit the existing program on the MNIST and NORB data sets.
\end{itemize}
\subsubsection{\href{http://www.cs.nyu.edu/~ylclab/data/norb-v1.0/}{NORB}  dataset}
This database is intended for experiments in 3D object recognition from shape. It contains images of 50 toys belonging to 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. The objects were imaged by two cameras under 6 lighting conditions, 9 elevations (30 to 70 degrees every 5 degrees), and 18 azimuths (0 to 340 every 20 degrees).

Popular method done on this data set is deep belief networks (\href{http://deeplearning.net/tutorial/DBN.html}{DBN}). Vinod Nair and Geoffrey E. Hinton at University of Toronto have a paper (\textit{3D Object Recognition with Deep Belief Nets}) on applying DBN on this data set.

\subsubsection{\href{http://yann.lecun.com/exdb/mnist/}{MNIST} dataset}
The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.

Many methods including linear classifier, KNN, SVM, etc have been tested with this training set and test set. From the deep learning aspect, convolutional net is applied to this data set and gives a relatively satisfied result. 


\subsection{A review of Curriculum Learning by Yanqian Wang}

Curriculum learning inspired by the "organized" learning processes of humans can benefit machine learning algorithms. Instead of having data randomly presented, curriculum learning strategy orders the data prior to the training boosting the convergence of learning algorithm. However, while some curriculum strategies are found to be effective, some others are actually useless. Challenges are to understand the difference of those successful strategies from the failed ones and how to generate better curriculum strategies. 

The review of this field will include the current strategies of curriculum learning and their application and effectiveness. 
This review should address towards the questions below.

\begin{itemize}
\item The reason why curriculum learning can help the training from faster convergence to better results.
\item The differences between successful strategies and ineffective strategies.
\item The dependence of the effectiveness of the strategies on the types of data.
\item The generalization of the curriculum learning as a unsupervised pre-training.
\item The limitation and potential of this learning strategy.
\item The development of new/better curriculum strategies.
\end{itemize}

\section{New application and methodology development}
\begin{itemize}
\item Develop curriculum learning strategies for faster convergence (may get help from out-of-field studies)
\item Apply deep learning techniques to HCP data. The objective of this application needs further discussions.
\end{itemize}



\section{ Plan of progress }
A first draft of review report will be done by Nov.7th. The efforts towards new application and methodology then will be made by both authors of this proposal starting from November.


\end{document}